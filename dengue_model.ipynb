{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umidmin               13\n",
      "umidmed               13\n",
      "umidmax               13\n",
      "tempmin                0\n",
      "tempmed               13\n",
      "tempmax               13\n",
      "precipitacao total     0\n",
      "casos                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('barueri_dengue_filtered.csv').drop('data inicial semana', axis=1).drop('month', axis=1)\n",
    "\n",
    "# Check for NaN or infinite values\n",
    "print(data.isna().sum())\n",
    "# print(np.isfinite(data).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('barueri_dengue_filtered.csv').drop('data inicial semana', axis=1).drop('month', axis=1)\n",
    "\n",
    "data_filled = data.fillna(data.mean())\n",
    "\n",
    "X, Y = data_filled.drop('casos', axis=1), data_filled['casos']\n",
    "\n",
    "X_dev, X_test, Y_dev, Y_test = train_test_split(X, Y, test_size=0.7, random_state=3)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_dev, Y_dev, test_size=0.5, random_state=3)\n",
    "\n",
    "x_test = torch.FloatTensor(X_test.values)\n",
    "y_test = torch.FloatTensor(Y_test.values)\n",
    "x_val = torch.FloatTensor(X_val.values)\n",
    "y_val = torch.FloatTensor(Y_val.values)\n",
    "x_train = torch.FloatTensor(X_train.values)\n",
    "y_train = torch.FloatTensor(Y_train.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Casos(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Casos, self).__init__()\n",
    "        self.rede = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.rede(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]\n",
    "model = Casos(input_dim)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, optimizer, loss_function, x_train, y_train, x_val, y_val, num_epochs, train_losses, val_losses):\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output_train = model(x_train)\n",
    "\n",
    "        # Calculate training loss\n",
    "        loss_train = loss_function(output_train, y_train.view(-1, 1))  # Reshape y_train\n",
    "\n",
    "        # Backward pass\n",
    "        loss_train.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation phase\n",
    "        output_val = model(x_val)\n",
    "        loss_val = loss_function(output_val, y_val.view(-1, 1))  # Reshape y_val\n",
    "\n",
    "        # Store losses\n",
    "        train_losses[epoch] = loss_train.item()\n",
    "        val_losses[epoch] = loss_val.item()\n",
    "\n",
    "        # Print progress every 500 epochs\n",
    "        if (epoch + 1) % 500 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {loss_train.item():.4f}, Val Loss: {loss_val.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/10000, Train Loss: 22963.4492, Val Loss: 19249.8047\n",
      "Epoch 1000/10000, Train Loss: 22647.9414, Val Loss: 19082.3164\n",
      "Epoch 1500/10000, Train Loss: 22625.8359, Val Loss: 19104.3457\n",
      "Epoch 2000/10000, Train Loss: 22625.4121, Val Loss: 19110.4766\n",
      "Epoch 2500/10000, Train Loss: 19049.7051, Val Loss: 16740.5977\n",
      "Epoch 3000/10000, Train Loss: 16789.5332, Val Loss: 15427.8467\n",
      "Epoch 3500/10000, Train Loss: 15301.3506, Val Loss: 14976.3154\n",
      "Epoch 4000/10000, Train Loss: 14214.4404, Val Loss: 14854.4248\n",
      "Epoch 4500/10000, Train Loss: 13379.3564, Val Loss: 14633.6279\n",
      "Epoch 5000/10000, Train Loss: 13211.6211, Val Loss: 16525.1211\n",
      "Epoch 5500/10000, Train Loss: 11840.7832, Val Loss: 15446.6289\n",
      "Epoch 6000/10000, Train Loss: 9898.4395, Val Loss: 13195.1182\n",
      "Epoch 6500/10000, Train Loss: 9099.7041, Val Loss: 13732.5615\n",
      "Epoch 7000/10000, Train Loss: 8438.5303, Val Loss: 13892.8955\n",
      "Epoch 7500/10000, Train Loss: 7888.6548, Val Loss: 14010.3457\n",
      "Epoch 8000/10000, Train Loss: 7433.0933, Val Loss: 14550.7920\n",
      "Epoch 8500/10000, Train Loss: 7062.4160, Val Loss: 14938.5225\n",
      "Epoch 9000/10000, Train Loss: 6767.5962, Val Loss: 15614.9004\n",
      "Epoch 9500/10000, Train Loss: 6529.4282, Val Loss: 16556.7930\n",
      "Epoch 10000/10000, Train Loss: 6338.5352, Val Loss: 16643.6699\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15000\n",
    "train_losses = np.zeros(num_epochs)\n",
    "val_losses = np.zeros(num_epochs)\n",
    "train_network(model, optimizer, criterion, x_train, y_train, x_val, y_val, num_epochs, train_losses, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
