{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers: 88\n",
      "       umidmin    umidmed     umidmax    tempmin    tempmed    tempmax  \\\n",
      "0    63.334366  86.488957   99.304751  18.730769  21.795150  26.653846   \n",
      "1    85.166191  86.695892   88.244707  21.882353  22.215686  22.588235   \n",
      "2    94.158321  94.585553   95.012784  20.857143  20.928571  21.000000   \n",
      "45   56.043362  80.964771   98.259046  17.428571  20.378402  24.571429   \n",
      "46   61.510815  84.295943   98.259188  18.571429  21.394048  26.142857   \n",
      "..         ...        ...         ...        ...        ...        ...   \n",
      "525  67.714286  82.209487   92.285714  19.285714  21.403812  25.285714   \n",
      "618  47.571429  79.537838   99.142857  18.285714  22.404165  28.142857   \n",
      "619  46.285714  82.611648  100.000000  16.857143  21.292295  27.857143   \n",
      "620  60.000000  87.771625  100.000000  16.714286  19.665284  24.714286   \n",
      "621  58.714286  84.591394   98.285714  19.000000  21.994909  27.571429   \n",
      "\n",
      "     precipitacao total  casos  \n",
      "0                  65.0     70  \n",
      "1                 121.4     39  \n",
      "2                  56.4     54  \n",
      "45                 14.2     59  \n",
      "46                  1.6     48  \n",
      "..                  ...    ...  \n",
      "525                77.0     39  \n",
      "618                22.4     44  \n",
      "619                88.4     55  \n",
      "620                44.8     75  \n",
      "621                 1.2     73  \n",
      "\n",
      "[88 rows x 8 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    622.000000\n",
       "mean      12.961415\n",
       "std       12.475577\n",
       "min        0.000000\n",
       "25%        4.000000\n",
       "50%        8.000000\n",
       "75%       17.750000\n",
       "max       38.375000\n",
       "Name: casos, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('barueri_dengue_filtered.csv').drop('data inicial semana', axis=1).drop('month', axis=1)\n",
    "\n",
    "data_filled = data.fillna(data.mean())\n",
    " # Identify outliers using IQR method\n",
    "Q1 = data_filled['casos'].quantile(0.25)\n",
    "Q3 = data_filled['casos'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Cap the outliers\n",
    "data_filled['casos'] = data_filled['casos'].apply(lambda x: upper_bound if x > upper_bound else (lower_bound if x < lower_bound else x))\n",
    "\n",
    "X, Y = data_filled[['tempmin','tempmed','tempmax','precipitacao total']], data_filled['casos']\n",
    "# Y.to_csv('casos.csv', index=False)\n",
    "Q1 = data['casos'].quantile(0.25)\n",
    "Q3 = data['casos'].quantile(0.75)\n",
    "\n",
    "# Calculate IQR (Interquartile Range)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the acceptable range\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = data[(data['casos'] < lower_bound) | (data['casos'] > upper_bound)]\n",
    "print(f'Number of outliers: {len(outliers)}')\n",
    "print(outliers)\n",
    "data_filled.casos.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(X, Y):    \n",
    "    X = data_filled[['tempmin', 'tempmed', 'tempmax', 'precipitacao total']]\n",
    "    Y = data_filled['casos']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    X_train, X_temp, Y_train, Y_temp = train_test_split(X_scaled, Y, test_size=0.3, random_state=3)\n",
    "    X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=3)\n",
    "    \n",
    "    x_train = torch.FloatTensor(X_train)\n",
    "    y_train = torch.FloatTensor(Y_train.values)\n",
    "    x_val = torch.FloatTensor(X_val)\n",
    "    y_val = torch.FloatTensor(Y_val.values)\n",
    "    x_test = torch.FloatTensor(X_test)\n",
    "    y_test = torch.FloatTensor(Y_test.values)\n",
    "    \n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Casos(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Casos, self).__init__()\n",
    "        self.rede = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Dropout(0.5),  # Dropout layer\n",
    "            # nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Dropout layer\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Dropout layer\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.rede(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]\n",
    "model = Casos(input_dim)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, optimizer, loss_function, x_train, y_train, x_val, y_val, num_epochs, train_losses, val_losses, device):\n",
    "    model.to(device)\n",
    "    x_train, y_train = x_train.to(device), y_train.to(device)\n",
    "    x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output_train = model(x_train)\n",
    "\n",
    "        # Calculate training loss\n",
    "        loss_train = loss_function(output_train, y_train.view(-1, 1))\n",
    "\n",
    "        # Backward pass\n",
    "        loss_train.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Validation phase\n",
    "            output_val = model(x_val)\n",
    "            loss_val = loss_function(output_val, y_val.view(-1, 1))\n",
    "\n",
    "        # Store losses\n",
    "        train_losses[epoch] = loss_train.item()\n",
    "        val_losses[epoch] = loss_val.item()\n",
    "\n",
    "        # Print progress every 500 epochs\n",
    "        if (epoch + 1) % 500 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {loss_train.item():.4f}, Val Loss: {loss_val.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'FloatFloatTensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(num_epochs)\n\u001b[1;32m      3\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(num_epochs)\n\u001b[0;32m----> 4\u001b[0m x_train, y_train, x_val, y_val, x_test, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m train_network(model, optimizer, criterion, x_train, y_train, x_val, y_val, num_epochs, train_losses, val_losses, device)\n",
      "Cell \u001b[0;32mIn[24], line 14\u001b[0m, in \u001b[0;36mload_and_preprocess_data\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     12\u001b[0m y_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(Y_train\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     13\u001b[0m x_val \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(X_val)\n\u001b[0;32m---> 14\u001b[0m y_val \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatFloatTensor\u001b[49m(Y_val\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m     15\u001b[0m x_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(X_test)\n\u001b[1;32m     16\u001b[0m y_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(Y_test\u001b[38;5;241m.\u001b[39mvalues)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'FloatFloatTensor'"
     ]
    }
   ],
   "source": [
    "num_epochs = 15000\n",
    "train_losses = np.zeros(num_epochs)\n",
    "val_losses = np.zeros(num_epochs)\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = load_and_preprocess_data(X, Y)\n",
    "train_network(model, optimizer, criterion, x_train, y_train, x_val, y_val, num_epochs, train_losses, val_losses, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 17199.6884234034\n"
     ]
    }
   ],
   "source": [
    "baseline_prediction = np.mean(Y)\n",
    "baseline_mse = np.mean((Y - baseline_prediction) ** 2)\n",
    "print(f'Baseline MSE: {baseline_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
